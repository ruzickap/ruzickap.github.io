<!doctype html><html lang="en" data-mode="dark"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Run the cheapest Amazon EKS" /><meta name="author" content="Petr Ruzicka" /><meta property="og:locale" content="en" /><meta name="description" content="Start the cheapest Amazon EKS using eksctl" /><meta property="og:description" content="Start the cheapest Amazon EKS using eksctl" /><link rel="canonical" href="https://ruzickap.github.io/posts/cheapest-amazon-eks/" /><meta property="og:url" content="https://ruzickap.github.io/posts/cheapest-amazon-eks/" /><meta property="og:site_name" content="Petr’s Blog" /><meta property="og:image" content="https://raw.githubusercontent.com/aws-samples/eks-workshop/65b766c494a5b4f5420b2912d8373c4957163541/static/images/icon-aws-amazon-eks.svg" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-11-27T00:00:00+01:00" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://raw.githubusercontent.com/aws-samples/eks-workshop/65b766c494a5b4f5420b2912d8373c4957163541/static/images/icon-aws-amazon-eks.svg" /><meta property="twitter:title" content="Run the cheapest Amazon EKS" /><meta name="twitter:site" content="@Ruzicka_Petr" /><meta name="twitter:creator" content="@Ruzicka_Petr" /><meta name="google-site-verification" content="4ugGShJoiB9veoPwFcMsMjzk-1BYbi5ozcSnovkBWtA" /><meta name="msvalidate.01" content="592AB158E3F9EF887F8DC8E69A2FF754" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Petr Ruzicka","url":"https://petr.ruzicka.dev"},"dateModified":"2025-06-11T16:18:06+02:00","datePublished":"2022-11-27T00:00:00+01:00","description":"Start the cheapest Amazon EKS using eksctl","headline":"Run the cheapest Amazon EKS","image":"https://raw.githubusercontent.com/aws-samples/eks-workshop/65b766c494a5b4f5420b2912d8373c4957163541/static/images/icon-aws-amazon-eks.svg","mainEntityOfPage":{"@type":"WebPage","@id":"https://ruzickap.github.io/posts/cheapest-amazon-eks/"},"url":"https://ruzickap.github.io/posts/cheapest-amazon-eks/"}</script><title>Run the cheapest Amazon EKS | Petr's Blog</title><link rel="icon" type="image/png" href="/assets/img/favicons/favicon-96x96.png" sizes="96x96"><link rel="icon" type="image/svg+xml" href="/assets/img/favicons/favicon.svg"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.36.4/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css"> <script src="/assets/js/dist/theme.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.18/dayjs.min.js,npm/dayjs@1.11.18/locale/en.js,npm/dayjs@1.11.18/plugin/relativeTime.js,npm/dayjs@1.11.18/plugin/localizedFormat.js,npm/tocbot@4.36.4/dist/tocbot.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> document.addEventListener('DOMContentLoaded', () => { const pv = document.getElementById('pageviews'); if (pv !== null) { const uri = location.pathname.replace(/\/$/, ''); const url = `https://ruzickap-github-io.goatcounter.com/counter/${encodeURIComponent(uri)}.json`; fetch(url) .then((response) => response.json()) .then((data) => { const count = data.count.replace(/\D/g, ''); pv.innerText = new Intl.NumberFormat().format(count); }) .catch((error) => { pv.innerText = '1'; }); } }); </script> <script defer src="/app.min.js?baseurl=&register=true" ></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-64WRCWDZM8"></script> <script> document.addEventListener('DOMContentLoaded', () => { window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'G-64WRCWDZM8'); }); </script> <script async src="https://gc.zgo.at/count.js" data-goatcounter="https://ruzickap-github-io.goatcounter.com/count" ></script> <script defer src="https://cloud.umami.is/script.js" data-website-id="380ea41a-7d5f-4423-8e13-03151bde195f" ></script> <script defer src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon='{"token": "3ppVAbe7E50OYFNqyhCNM1wmS_uQ1FrH5PHYn9d-"}' ></script><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"><img src="https://0.gravatar.com/avatar/5484c0fd9f98e2ffd9212b158931bf4b?s=200" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a> <a class="site-title d-block" href="/">Petr's Blog</a><p class="site-subtitle fst-italic mb-0">DevOps • GitOps • K8s</p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/projects/" class="nav-link"> <i class="fa-fw fas fa-project-diagram"></i> <span>PROJECTS</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle"></i> <span>ABOUT</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <a href="https://github.com/ruzickap" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github"></i> </a> <a href="javascript:location.href = 'mailto:' + ['petr.ruzicka','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://www.linkedin.com/in/petrruzicka/" aria-label="linkedin" target="_blank" rel="noopener noreferrer" > <i class="fab fa-linkedin"></i> </a> <a href="https://petr.ruzicka.dev" aria-label="homepage" target="_blank" rel="noopener noreferrer" > <i class="fas fa-home"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></aside><div id="main-wrapper" class="d-flex justify-content-center"><div class="container d-flex flex-column px-xxl-5"><header id="topbar-wrapper" class="flex-shrink-0" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100" ><nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/">Home</a> </span> <span>Run the cheapest Amazon EKS</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link" aria-label="Sidebar"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div><button type="button" id="search-trigger" class="btn btn-link" aria-label="Search"> <i class="fas fa-search fa-fw"></i> </button> <search id="search" class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..." > </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button></div></header><div class="row flex-grow-1"><main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"><article class="px-1" data-toc="true"><header><h1 data-toc-skip>Run the cheapest Amazon EKS</h1><p class="post-desc fw-light mb-4">Start the cheapest Amazon EKS using eksctl</p><div class="post-meta text-muted"> <span> Posted <time data-ts="1669503600" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Nov 27, 2022 </time> </span> <span> Updated <time data-ts="1749651486" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Jun 11, 2025 </time> </span><div class="mt-3 mb-3"> <a href="https://raw.githubusercontent.com/aws-samples/eks-workshop/65b766c494a5b4f5420b2912d8373c4957163541/static/images/icon-aws-amazon-eks.svg" class="popup img-link preview-img shimmer"><img src="https://raw.githubusercontent.com/aws-samples/eks-workshop/65b766c494a5b4f5420b2912d8373c4957163541/static/images/icon-aws-amazon-eks.svg" alt="Preview Image" width="1200" height="630" loading="lazy"></a></div><div class="d-flex justify-content-between"> <span> By <em> <a href="https://petr.ruzicka.dev">Petr Ruzicka</a> </em> </span><div> <span> <em id="pageviews"> <i class="fas fa-spinner fa-spin small"></i> </em> views </span> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="3788 words" > <em>21 min</em> read</span></div></div></div></header><div id="toc-bar" class="d-flex align-items-center justify-content-between invisible"> <span class="label text-truncate">Run the cheapest Amazon EKS</span> <button type="button" class="toc-trigger btn me-1"> <i class="fa-solid fa-list-ul fa-fw"></i> </button></div><button id="toc-solo-trigger" type="button" class="toc-trigger btn btn-outline-secondary btn-sm"> <span class="label ps-2 pe-1">Contents</span> <i class="fa-solid fa-angle-right fa-fw"></i> </button> <dialog id="toc-popup" class="p-0"><div class="header d-flex flex-row align-items-center justify-content-between"><div class="label text-truncate py-2 ms-4">Run the cheapest Amazon EKS</div><button id="toc-popup-close" type="button" class="btn mx-1 my-1 opacity-75"> <i class="fas fa-close"></i> </button></div><div id="toc-popup-content" class="px-4 py-3 pb-4"></div></dialog><div class="content"><p>Sometimes, it’s necessary to save costs and run <a href="https://aws.amazon.com/eks/">Amazon EKS</a> in the most cost-effective way.</p><p>The following notes describe how to run <a href="https://aws.amazon.com/eks/">Amazon EKS</a> at the lowest possible price.</p><p>Requirements:</p><ul><li>Utilize two Availability Zones (AZs), or use a single zone if feasible to reduce costs associated with cross-AZ traffic<li>Use Spot instances<li>Choose a less expensive AWS region, such as <code class="language-plaintext highlighter-rouge">us-east-1</code><li>Employ the most price-efficient EC2 instance type, <code class="language-plaintext highlighter-rouge">t4g.medium</code> (2 CPUs, 4GB RAM), which uses <a href="https://aws.amazon.com/ec2/graviton/">AWS Graviton</a> processors based on ARM architecture<li>Use <a href="https://github.com/bottlerocket-os/bottlerocket">Bottlerocket OS</a> for a minimal operating system, CPU, and memory footprint<li>Use a <a href="https://aws.amazon.com/elasticloadbalancing/network-load-balancer/">Network Load Balancer (NLB)</a> as it is a cost-efficient and optimized load balancing solution<li>Configure worker nodes to run the maximum number of pods possible using the <code class="language-plaintext highlighter-rouge">max-pods-per-node</code> setting<ul><li><a href="https://stackoverflow.com/questions/57970896/pod-limit-on-node-aws-eks">https://stackoverflow.com/questions/57970896/pod-limit-on-node-aws-eks</a><li><a href="https://aws.amazon.com/blogs/containers/amazon-vpc-cni-increases-pods-per-node-limits/">https://aws.amazon.com/blogs/containers/amazon-vpc-cni-increases-pods-per-node-limits/</a></ul></ul><h2 id="build-amazon-eks-cluster"><span class="me-2">Build Amazon EKS cluster</span><a href="#build-amazon-eks-cluster" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="requirements"><span class="me-2">Requirements</span><a href="#requirements" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>You will need to configure the <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html">AWS CLI</a> and set up other necessary secrets and variables.</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="c"># AWS Credentials</span>
<span class="nb">export </span><span class="nv">AWS_ACCESS_KEY_ID</span><span class="o">=</span><span class="s2">"xxxxxxxxxxxxxxxxxx"</span>
<span class="nb">export </span><span class="nv">AWS_SECRET_ACCESS_KEY</span><span class="o">=</span><span class="s2">"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"</span>
<span class="nb">export </span><span class="nv">AWS_SESSION_TOKEN</span><span class="o">=</span><span class="s2">"xxxxxxxx"</span>
<span class="nb">export </span><span class="nv">AWS_ROLE_TO_ASSUME</span><span class="o">=</span><span class="s2">"arn:aws:iam::7xxxxxxxxxx7:role/Gixxxxxxxxxxxxxxxxxxxxle"</span>
<span class="nb">export </span><span class="nv">GOOGLE_CLIENT_ID</span><span class="o">=</span><span class="s2">"10xxxxxxxxxxxxxxxud.apps.googleusercontent.com"</span>
<span class="nb">export </span><span class="nv">GOOGLE_CLIENT_SECRET</span><span class="o">=</span><span class="s2">"GOxxxxxxxxxxxxxxxtw"</span>
</pre></table></code></div></div><p>If you would like to follow this document and its tasks, you will need to set up a few environment variables, such as:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="c"># AWS Region</span>
<span class="nb">export </span><span class="nv">AWS_DEFAULT_REGION</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">AWS_DEFAULT_REGION</span><span class="k">:-</span><span class="nv">us</span><span class="p">-east-1</span><span class="k">}</span><span class="s2">"</span>
<span class="c"># Hostname / FQDN definitions</span>
<span class="nb">export </span><span class="nv">CLUSTER_FQDN</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">:-</span><span class="nv">k01</span><span class="p">.k8s.mylabs.dev</span><span class="k">}</span><span class="s2">"</span>
<span class="c"># Base Domain: k8s.mylabs.dev</span>
<span class="nb">export </span><span class="nv">BASE_DOMAIN</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="p">#*.</span><span class="k">}</span><span class="s2">"</span>
<span class="c"># Cluster Name: k01</span>
<span class="nb">export </span><span class="nv">CLUSTER_NAME</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="p">%%.*</span><span class="k">}</span><span class="s2">"</span>
<span class="nb">export </span><span class="nv">MY_EMAIL</span><span class="o">=</span><span class="s2">"petr.ruzicka@gmail.com"</span>
<span class="nb">export </span><span class="nv">TMP_DIR</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">:-${</span><span class="nv">PWD</span><span class="k">}}</span><span class="s2">"</span>
<span class="nb">export </span><span class="nv">KUBECONFIG</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">KUBECONFIG</span><span class="k">:-${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="p">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="p">/kubeconfig-</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="p">.conf</span><span class="k">}</span><span class="s2">"</span>
<span class="c"># Tags used to tag the AWS resources</span>
<span class="nb">export </span><span class="nv">TAGS</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">TAGS</span><span class="k">:-</span><span class="nv">Owner</span><span class="p">=</span><span class="k">${</span><span class="nv">MY_EMAIL</span><span class="k">}</span><span class="p">,Environment=dev,Cluster=</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}}</span><span class="s2">"</span>
<span class="nv">AWS_ACCOUNT_ID</span><span class="o">=</span><span class="si">$(</span>aws sts get-caller-identity <span class="nt">--query</span> <span class="s2">"Account"</span> <span class="nt">--output</span> text<span class="si">)</span> <span class="o">&amp;&amp;</span> <span class="nb">export </span>AWS_ACCOUNT_ID
<span class="nb">mkdir</span> <span class="nt">-pv</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">"</span>
</pre></table></code></div></div><p>Verify that all necessary variables have been set:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>: <span class="s2">"</span><span class="k">${</span><span class="nv">AWS_ACCESS_KEY_ID</span><span class="p">?</span><span class="k">}</span><span class="s2">"</span>
: <span class="s2">"</span><span class="k">${</span><span class="nv">AWS_DEFAULT_REGION</span><span class="p">?</span><span class="k">}</span><span class="s2">"</span>
: <span class="s2">"</span><span class="k">${</span><span class="nv">AWS_SECRET_ACCESS_KEY</span><span class="p">?</span><span class="k">}</span><span class="s2">"</span>
: <span class="s2">"</span><span class="k">${</span><span class="nv">AWS_ROLE_TO_ASSUME</span><span class="p">?</span><span class="k">}</span><span class="s2">"</span>
: <span class="s2">"</span><span class="k">${</span><span class="nv">GOOGLE_CLIENT_ID</span><span class="p">?</span><span class="k">}</span><span class="s2">"</span>
: <span class="s2">"</span><span class="k">${</span><span class="nv">GOOGLE_CLIENT_SECRET</span><span class="p">?</span><span class="k">}</span><span class="s2">"</span>

<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MY_EMAIL</span><span class="k">}</span><span class="s2"> | </span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2"> | </span><span class="k">${</span><span class="nv">BASE_DOMAIN</span><span class="k">}</span><span class="s2"> | </span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="se">\n</span><span class="k">${</span><span class="nv">TAGS</span><span class="k">}</span><span class="s2">"</span>
</pre></table></code></div></div><p>Install the necessary tools:</p><blockquote class="prompt-tip"><p>You can skip these steps if you have all the required software already installed.</p></blockquote><ul><li><a href="https://aws.amazon.com/cli/">AWS CLI</a><li><a href="https://eksctl.io/">eksctl</a><li><a href="https://github.com/kubernetes/kubectl">kubectl</a><li><a href="https://github.com/helm/helm">helm</a></ul><h2 id="configure-aws-route-53-domain-delegation"><span class="me-2">Configure AWS Route 53 Domain delegation</span><a href="#configure-aws-route-53-domain-delegation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><blockquote class="prompt-info"><p>The DNS delegation steps should only be done once.</p></blockquote><p>Create a DNS zone for the EKS clusters:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="nb">export </span><span class="nv">CLOUDFLARE_EMAIL</span><span class="o">=</span><span class="s2">"petr.ruzicka@gmail.com"</span>
<span class="nb">export </span><span class="nv">CLOUDFLARE_API_KEY</span><span class="o">=</span><span class="s2">"1xxxxxxxxx0"</span>

aws route53 create-hosted-zone <span class="nt">--output</span> json <span class="se">\</span>
  <span class="nt">--name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BASE_DOMAIN</span><span class="k">}</span><span class="s2">"</span> <span class="se">\</span>
  <span class="nt">--caller-reference</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">date</span><span class="si">)</span><span class="s2">"</span> <span class="se">\</span>
  <span class="nt">--hosted-zone-config</span><span class="o">=</span><span class="s2">"{</span><span class="se">\"</span><span class="s2">Comment</span><span class="se">\"</span><span class="s2">: </span><span class="se">\"</span><span class="s2">Created by petr.ruzicka@gmail.com</span><span class="se">\"</span><span class="s2">, </span><span class="se">\"</span><span class="s2">PrivateZone</span><span class="se">\"</span><span class="s2">: false}"</span> | jq
</pre></table></code></div></div><p><a href="/assets/img/posts/2022/2022-11-27-cheapest-amazon-eks/route53-hostedzones-k8s.mylabs.dev-1.avif" class="popup img-link shimmer"><img src="/assets/img/posts/2022/2022-11-27-cheapest-amazon-eks/route53-hostedzones-k8s.mylabs.dev-1.avif" alt="Route53 k8s.mylabs.dev zone" loading="lazy"></a> <em>Route53 k8s.mylabs.dev zone</em></p><p>Use your domain registrar to change the nameservers for your zone (e.g., <code class="language-plaintext highlighter-rouge">mylabs.dev</code>) to use the Amazon Route 53 nameservers. You can find the required Route 53 nameservers as follows:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="nv">NEW_ZONE_ID</span><span class="o">=</span><span class="si">$(</span>aws route53 list-hosted-zones <span class="nt">--query</span> <span class="s2">"HostedZones[?Name==</span><span class="se">\`</span><span class="k">${</span><span class="nv">BASE_DOMAIN</span><span class="k">}</span><span class="s2">.</span><span class="se">\`</span><span class="s2">].Id"</span> <span class="nt">--output</span> text<span class="si">)</span>
<span class="nv">NEW_ZONE_NS</span><span class="o">=</span><span class="si">$(</span>aws route53 get-hosted-zone <span class="nt">--output</span> json <span class="nt">--id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">NEW_ZONE_ID</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"DelegationSet.NameServers"</span><span class="si">)</span>
<span class="nv">NEW_ZONE_NS1</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="s2">"</span><span class="k">${</span><span class="nv">NEW_ZONE_NS</span><span class="k">}</span><span class="s2">"</span> | jq <span class="nt">-r</span> <span class="s2">".[0]"</span><span class="si">)</span>
<span class="nv">NEW_ZONE_NS2</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="s2">"</span><span class="k">${</span><span class="nv">NEW_ZONE_NS</span><span class="k">}</span><span class="s2">"</span> | jq <span class="nt">-r</span> <span class="s2">".[1]"</span><span class="si">)</span>
</pre></table></code></div></div><p>Create the NS record in <code class="language-plaintext highlighter-rouge">k8s.mylabs.dev</code> (your <code class="language-plaintext highlighter-rouge">BASE_DOMAIN</code>) for proper zone delegation. This step depends on your domain registrar; I use Cloudflare and automate this with Ansible:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>ansible <span class="nt">-m</span> cloudflare_dns <span class="nt">-c</span> <span class="nb">local</span> <span class="nt">-i</span> <span class="s2">"localhost,"</span> localhost <span class="nt">-a</span> <span class="s2">"zone=mylabs.dev record=</span><span class="k">${</span><span class="nv">BASE_DOMAIN</span><span class="k">}</span><span class="s2"> type=NS value=</span><span class="k">${</span><span class="nv">NEW_ZONE_NS1</span><span class="k">}</span><span class="s2"> solo=true proxied=no account_email=</span><span class="k">${</span><span class="nv">CLOUDFLARE_EMAIL</span><span class="k">}</span><span class="s2"> account_api_token=</span><span class="k">${</span><span class="nv">CLOUDFLARE_API_KEY</span><span class="k">}</span><span class="s2">"</span>
ansible <span class="nt">-m</span> cloudflare_dns <span class="nt">-c</span> <span class="nb">local</span> <span class="nt">-i</span> <span class="s2">"localhost,"</span> localhost <span class="nt">-a</span> <span class="s2">"zone=mylabs.dev record=</span><span class="k">${</span><span class="nv">BASE_DOMAIN</span><span class="k">}</span><span class="s2"> type=NS value=</span><span class="k">${</span><span class="nv">NEW_ZONE_NS2</span><span class="k">}</span><span class="s2"> solo=false proxied=no account_email=</span><span class="k">${</span><span class="nv">CLOUDFLARE_EMAIL</span><span class="k">}</span><span class="s2"> account_api_token=</span><span class="k">${</span><span class="nv">CLOUDFLARE_API_KEY</span><span class="k">}</span><span class="s2">"</span>
</pre></table></code></div></div><div class="language-console highlighter-rouge"><div class="code-header"> <span data-label-text="Console"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
</pre><td class="rouge-code"><pre><span class="gp">localhost | CHANGED =&gt;</span><span class="w"> </span><span class="o">{</span>
<span class="go">    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": true,
    "result": {
        "record": {
            "content": "ns-885.awsdns-46.net",
            "created_on": "2020-11-13T06:25:32.18642Z",
            "id": "dxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxb",
            "locked": false,
            "meta": {
                "auto_added": false,
                "managed_by_apps": false,
                "managed_by_argo_tunnel": false,
                "source": "primary"
            },
            "modified_on": "2020-11-13T06:25:32.18642Z",
            "name": "k8s.mylabs.dev",
            "proxiable": false,
            "proxied": false,
            "ttl": 1,
            "type": "NS",
            "zone_id": "2xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxe",
            "zone_name": "mylabs.dev"
        }
    }
}
</span><span class="gp">localhost | CHANGED =&gt;</span><span class="w"> </span><span class="o">{</span>
<span class="go">    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": true,
    "result": {
        "record": {
            "content": "ns-1692.awsdns-19.co.uk",
            "created_on": "2020-11-13T06:25:37.605605Z",
            "id": "9xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxb",
            "locked": false,
            "meta": {
                "auto_added": false,
                "managed_by_apps": false,
                "managed_by_argo_tunnel": false,
                "source": "primary"
            },
            "modified_on": "2020-11-13T06:25:37.605605Z",
            "name": "k8s.mylabs.dev",
            "proxiable": false,
            "proxied": false,
            "ttl": 1,
            "type": "NS",
            "zone_id": "2xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxe",
            "zone_name": "mylabs.dev"
        }
    }
}
</span></pre></table></code></div></div><p><a href="/assets/img/posts/2022/2022-11-27-cheapest-amazon-eks/cloudflare-mylabs-dev-dns-records.avif" class="popup img-link shimmer"><img src="/assets/img/posts/2022/2022-11-27-cheapest-amazon-eks/cloudflare-mylabs-dev-dns-records.avif" alt="CloudFlare mylabs.dev zone" loading="lazy"></a> <em>CloudFlare mylabs.dev zone</em></p><h3 id="create-route53"><span class="me-2">Create Route53</span><a href="#create-route53" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Create a CloudFormation template that defines the <a href="https://aws.amazon.com/route53/">Route53</a> zone.</p><p>Add the new domain <code class="language-plaintext highlighter-rouge">CLUSTER_FQDN</code> to Route 53 and configure DNS delegation from the <code class="language-plaintext highlighter-rouge">BASE_DOMAIN</code>.</p><p>Create the Route53 zone:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
</pre><td class="rouge-code"><pre><span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/aws-cf-route53.yml"</span> <span class="o">&lt;&lt;</span> <span class="sh">\</span><span class="no">EOF</span><span class="sh">
AWSTemplateFormatVersion: 2010-09-09
Description: Route53 entries

Parameters:
  BaseDomain:
    Description: "Base domain where cluster domains + their subdomains will live. Ex: k8s.mylabs.dev"
    Type: String
  ClusterFQDN:
    Description: "Cluster FQDN. (domain for all applications) Ex: k01.k8s.mylabs.dev"
    Type: String
Resources:
  HostedZone:
    Type: AWS::Route53::HostedZone
    Properties:
      Name: !Ref ClusterFQDN
  RecordSet:
    Type: AWS::Route53::RecordSet
    Properties:
      HostedZoneName: !Sub "</span><span class="k">${</span><span class="nv">BaseDomain</span><span class="k">}</span><span class="sh">."
      Name: !Ref ClusterFQDN
      Type: NS
      TTL: 60
      ResourceRecords: !GetAtt HostedZone.NameServers
</span><span class="no">EOF

</span><span class="k">if</span> <span class="o">[[</span> <span class="si">$(</span>aws cloudformation list-stacks <span class="nt">--stack-status-filter</span> CREATE_COMPLETE <span class="nt">--query</span> <span class="s2">"StackSummaries[?starts_with(StackName, </span><span class="se">\`</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">-route53</span><span class="se">\`</span><span class="s2">) == </span><span class="se">\`</span><span class="s2">true</span><span class="se">\`</span><span class="s2">].StackName"</span> <span class="nt">--output</span> text<span class="si">)</span> <span class="o">==</span> <span class="s2">""</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
  <span class="c"># shellcheck disable=SC2001</span>
  <span class="nb">eval </span>aws cloudformation create-stack <span class="se">\</span>
    <span class="nt">--parameters</span> <span class="s2">"ParameterKey=BaseDomain,ParameterValue=</span><span class="k">${</span><span class="nv">BASE_DOMAIN</span><span class="k">}</span><span class="s2"> ParameterKey=ClusterFQDN,ParameterValue=</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">"</span> <span class="se">\</span>
    <span class="nt">--stack-name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">-route53"</span> <span class="se">\</span>
    <span class="nt">--template-body</span> <span class="s2">"file://</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/aws-cf-route53.yml"</span> <span class="se">\</span>
    <span class="nt">--tags</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">echo</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TAGS</span><span class="k">}</span><span class="s2">"</span> | <span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">'s/\([^=]*\)=\([^,]*\),*/Key=\1,Value=\2 /g'</span><span class="si">)</span><span class="s2">"</span> <span class="o">||</span> <span class="nb">true
</span><span class="k">fi</span>
</pre></table></code></div></div><p>After running the CloudFormation stack, you should see the following Route53 zones:</p><p><a href="/assets/img/posts/2022/2022-11-27-cheapest-amazon-eks/route53-hostedzones-k01.k8s.mylabs.dev.avif" class="popup img-link shimmer"><img src="/assets/img/posts/2022/2022-11-27-cheapest-amazon-eks/route53-hostedzones-k01.k8s.mylabs.dev.avif" alt="Route53 k01.k8s.mylabs.dev zone" loading="lazy"></a> <em>Route53 k01.k8s.mylabs.dev zone</em></p><p><a href="/assets/img/posts/2022/2022-11-27-cheapest-amazon-eks/route53-hostedones-k8s.mylabs.dev-2.avif" class="popup img-link shimmer"><img src="/assets/img/posts/2022/2022-11-27-cheapest-amazon-eks/route53-hostedones-k8s.mylabs.dev-2.avif" alt="Route53 k8s.mylabs.dev zone" loading="lazy"></a> <em>Route53 k8s.mylabs.dev zone</em></p><h2 id="create-amazon-eks"><span class="me-2">Create Amazon EKS</span><a href="#create-amazon-eks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>I will use <a href="https://eksctl.io/">eksctl</a> to create the Amazon EKS cluster.</p><p><a href="https://raw.githubusercontent.com/weaveworks/eksctl/2b1ec6223c4e7cb8103c08162e6de8ced47376f9/userdocs/src/img/eksctl.png" class="popup img-link shimmer"><img src="https://raw.githubusercontent.com/weaveworks/eksctl/2b1ec6223c4e7cb8103c08162e6de8ced47376f9/userdocs/src/img/eksctl.png" alt="eksctl" width="700" loading="lazy"></a></p><p>Create the <a href="https://aws.amazon.com/eks/">Amazon EKS</a> cluster using <a href="https://eksctl.io/">eksctl</a>:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
</pre><td class="rouge-code"><pre><span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/eksctl-</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">.yml"</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh">
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: </span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="sh">
  region: </span><span class="k">${</span><span class="nv">AWS_DEFAULT_REGION</span><span class="k">}</span><span class="sh">
  tags:
    karpenter.sh/discovery: </span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="sh">
    </span><span class="si">$(</span><span class="nb">echo</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TAGS</span><span class="k">}</span><span class="s2">"</span> | <span class="nb">sed</span> <span class="s2">"s/,/</span><span class="se">\\</span><span class="s2">n    /g; s/=/: /g"</span><span class="si">)</span><span class="sh">
availabilityZones:
  - </span><span class="k">${</span><span class="nv">AWS_DEFAULT_REGION</span><span class="k">}</span><span class="sh">a
  - </span><span class="k">${</span><span class="nv">AWS_DEFAULT_REGION</span><span class="k">}</span><span class="sh">b
iam:
  withOIDC: true
  serviceAccounts:
    - metadata:
        name: cert-manager
        namespace: cert-manager
      wellKnownPolicies:
        certManager: true
      roleName: eksctl-</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="sh">-irsa-cert-manager
    - metadata:
        name: external-dns
        namespace: external-dns
      wellKnownPolicies:
        externalDNS: true
      roleName: eksctl-</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="sh">-irsa-external-dns
# Allow users which are consuming the AWS_ROLE_TO_ASSUME to access the EKS
iamIdentityMappings:
  - arn: arn:aws:iam::</span><span class="k">${</span><span class="nv">AWS_ACCOUNT_ID</span><span class="k">}</span><span class="sh">:role/admin
    groups:
      - system:masters
    username: admin
karpenter:
  # renovate: datasource=github-tags depName=aws/karpenter extractVersion=^(?&lt;version&gt;.*)$
  version: v0.31.4
  createServiceAccount: true
  withSpotInterruptionQueue: true
addons:
  - name: vpc-cni
    # min version 1.14.0
    version: latest
    configurationValues: |-
      enableNetworkPolicy: "true"
      env:
        ENABLE_PREFIX_DELEGATION: "true"
  - name: kube-proxy
  - name: coredns
  - name: aws-ebs-csi-driver
managedNodeGroups:
  - name: mng01-ng
    amiFamily: Bottlerocket
    # Minimal instance type for running add-ons + karpenter - ARM t4g.medium: 4.0 GiB, 2 vCPUs - 0.0336 hourly
    # Minimal instance type for running add-ons + karpenter - X86 t3a.medium: 4.0 GiB, 2 vCPUs - 0.0336 hourly
    instanceType: t4g.medium
    # Due to karpenter we need 2 instances
    desiredCapacity: 2
    availabilityZones:
      - </span><span class="k">${</span><span class="nv">AWS_DEFAULT_REGION</span><span class="k">}</span><span class="sh">a
    minSize: 2
    maxSize: 5
    volumeSize: 20
    disablePodIMDS: true
    volumeEncrypted: true
    # For instances with less than 30 vCPUs the maximum number is 110 and for all other instances the maximum number is 250
    # https://docs.aws.amazon.com/eks/latest/userguide/cni-increase-ip-addresses.html
    maxPodsPerNode: 110
</span><span class="no">EOF
</span></pre></table></code></div></div><p>Get the kubeconfig file to access the cluster:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="k">if</span> <span class="o">[[</span> <span class="o">!</span> <span class="nt">-s</span> <span class="s2">"</span><span class="k">${</span><span class="nv">KUBECONFIG</span><span class="k">}</span><span class="s2">"</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then
  if</span> <span class="o">!</span> eksctl get clusters <span class="nt">--name</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">"</span> &amp;&gt; /dev/null<span class="p">;</span> <span class="k">then
    </span>eksctl create cluster <span class="nt">--config-file</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/eksctl-</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">.yml"</span> <span class="nt">--kubeconfig</span> <span class="s2">"</span><span class="k">${</span><span class="nv">KUBECONFIG</span><span class="k">}</span><span class="s2">"</span>
  <span class="k">else
    </span>eksctl utils write-kubeconfig <span class="nt">--cluster</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--kubeconfig</span> <span class="s2">"</span><span class="k">${</span><span class="nv">KUBECONFIG</span><span class="k">}</span><span class="s2">"</span>
  <span class="k">fi
fi

</span>aws eks update-kubeconfig <span class="nt">--name</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">"</span>
</pre></table></code></div></div><h3 id="karpenter"><span class="me-2">Karpenter</span><a href="#karpenter" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="https://karpenter.sh/">Karpenter</a> is a Kubernetes node autoscaler built for flexibility, performance, and simplicity.</p><p><a href="https://raw.githubusercontent.com/aws/karpenter/efa141bc7276db421980bf6e6483d9856929c1e9/website/static/banner.png" class="popup img-link shimmer"><img src="https://raw.githubusercontent.com/aws/karpenter/efa141bc7276db421980bf6e6483d9856929c1e9/website/static/banner.png" alt="Karpenter" width="500" loading="lazy"></a></p><p>Configure <a href="https://karpenter.sh/">Karpenter</a> by applying the following provisioner definition:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
</pre><td class="rouge-code"><pre><span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/k8s-karpenter-provisioner.yml"</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: karpenter.sh/v1alpha5
kind: Provisioner
metadata:
  name: default
spec:
  # Enables consolidation which attempts to reduce cluster cost by both removing
  # un-needed nodes and down-sizing those that can't be removed.
  # https://youtu.be/OB7IZolZk78?t=2629
  consolidation:
    enabled: true
  requirements:
    - key: karpenter.sh/capacity-type
      operator: In
      values: ["spot", "on-demand"]
    - key: kubernetes.io/arch
      operator: In
      values: ["amd64", "arm64"]
    - key: "topology.kubernetes.io/zone"
      operator: In
      values: ["</span><span class="k">${</span><span class="nv">AWS_DEFAULT_REGION</span><span class="k">}</span><span class="sh">a"]
    - key: karpenter.k8s.aws/instance-family
      operator: In
      values: ["t3a", "t4g"]
  kubeletConfiguration:
    maxPods: 110
  # Resource limits constrain the total size of the cluster.
  # Limits prevent Karpenter from creating new instances once the limit is exceeded.
  limits:
    resources:
      cpu: 8
      memory: 32Gi
  providerRef:
    name: default
  # Labels are arbitrary key-values that are applied to all nodes
  labels:
    managedBy: karpenter
    provisioner: default
---
apiVersion: karpenter.k8s.aws/v1alpha1
kind: AWSNodeTemplate
metadata:
  name: default
spec:
  amiFamily: Bottlerocket
  subnetSelector:
    karpenter.sh/discovery: </span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="sh">
  securityGroupSelector:
    karpenter.sh/discovery: </span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="sh">
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 2Gi
        volumeType: gp3
        encrypted: true
    - deviceName: /dev/xvdb
      ebs:
        volumeSize: 20Gi
        volumeType: gp3
        encrypted: true
  tags:
    KarpenerProvisionerName: "default"
    Name: "</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="sh">-karpenter"
    </span><span class="si">$(</span><span class="nb">echo</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TAGS</span><span class="k">}</span><span class="s2">"</span> | <span class="nb">sed</span> <span class="s2">"s/,/</span><span class="se">\\</span><span class="s2">n    /g; s/=/: /g"</span><span class="si">)</span><span class="sh">
</span><span class="no">EOF
</span></pre></table></code></div></div><h3 id="aws-node-termination-handler"><span class="me-2">aws-node-termination-handler</span><a href="#aws-node-termination-handler" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The <a href="https://github.com/aws/aws-node-termination-handler">AWS Node Termination Handler</a> gracefully handles EC2 instance shutdowns within Kubernetes.</p><p>Install the <code class="language-plaintext highlighter-rouge">aws-node-termination-handler</code> <a href="https://artifacthub.io/packages/helm/aws/aws-node-termination-handler">Helm chart</a> and modify its <a href="https://github.com/aws/aws-node-termination-handler/blob/main/config/helm/aws-node-termination-handler/values.yaml">default values</a> as shown below:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="c"># renovate: datasource=helm depName=aws-node-termination-handler registryUrl=https://aws.github.io/eks-charts</span>
<span class="nv">AWS_NODE_TERMINATION_HANDLER_HELM_CHART_VERSION</span><span class="o">=</span><span class="s2">"0.21.0"</span>

helm repo add <span class="nt">--force-update</span> eks https://aws.github.io/eks-charts/
<span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-aws-node-termination-handler.yml"</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh">
awsRegion: </span><span class="k">${</span><span class="nv">AWS_DEFAULT_REGION</span><span class="k">}</span><span class="sh">
</span><span class="no">EOF
</span>helm upgrade <span class="nt">--install</span> <span class="nt">--version</span> <span class="s2">"</span><span class="k">${</span><span class="nv">AWS_NODE_TERMINATION_HANDLER_HELM_CHART_VERSION</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--namespace</span> kube-system <span class="nt">--values</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-aws-node-termination-handler.yml"</span> aws-node-termination-handler eks/aws-node-termination-handler
</pre></table></code></div></div><h3 id="mailhog"><span class="me-2">mailhog</span><a href="#mailhog" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>MailHog will be used to receive email alerts from Prometheus.</p><p><a href="https://raw.githubusercontent.com/sj26/mailcatcher/main/assets/images/logo_large.png" class="popup img-link shimmer"><img src="https://raw.githubusercontent.com/sj26/mailcatcher/main/assets/images/logo_large.png" alt="MailHog" width="200" loading="lazy"></a></p><p>Install the <code class="language-plaintext highlighter-rouge">mailhog</code> <a href="https://artifacthub.io/packages/helm/codecentric/mailhog">Helm chart</a> and modify its <a href="https://github.com/codecentric/helm-charts/blob/mailhog-5.2.3/charts/mailhog/values.yaml">default values</a>:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre><td class="rouge-code"><pre><span class="c"># renovate: datasource=helm depName=mailhog registryUrl=https://codecentric.github.io/helm-charts</span>
<span class="nv">MAILHOG_HELM_CHART_VERSION</span><span class="o">=</span><span class="s2">"5.2.3"</span>

helm repo add <span class="nt">--force-update</span> codecentric https://codecentric.github.io/helm-charts
<span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-mailhog.yml"</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh">
image:
  repository: docker.io/cd2team/mailhog
  tag: "1663459324"
ingress:
  enabled: true
  annotations:
    forecastle.stakater.com/expose: "true"
    forecastle.stakater.com/icon: https://raw.githubusercontent.com/sj26/mailcatcher/main/assets/images/logo_large.png
    forecastle.stakater.com/appName: Mailhog
    nginx.ingress.kubernetes.io/auth-url: https://oauth2-proxy.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">/oauth2/auth
    nginx.ingress.kubernetes.io/auth-signin: https://oauth2-proxy.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">/oauth2/start?rd=</span><span class="se">\$</span><span class="sh">scheme://</span><span class="se">\$</span><span class="sh">host</span><span class="se">\$</span><span class="sh">request_uri
  ingressClassName: nginx
  hosts:
    - host: mailhog.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls:
    - hosts:
        - mailhog.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
</span><span class="no">EOF
</span>helm upgrade <span class="nt">--install</span> <span class="nt">--version</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MAILHOG_HELM_CHART_VERSION</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--namespace</span> mailhog <span class="nt">--create-namespace</span> <span class="nt">--values</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-mailhog.yml"</span> mailhog codecentric/mailhog
</pre></table></code></div></div><h3 id="kube-prometheus-stack"><span class="me-2">kube-prometheus-stack</span><a href="#kube-prometheus-stack" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The <a href="https://github.com/prometheus-operator/kube-prometheus">kube-prometheus-stack</a> is a collection of Kubernetes manifests, <a href="https://grafana.com/">Grafana</a> dashboards, and <a href="https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/">Prometheus rules</a>. It’s combined with documentation and scripts to provide easy-to-operate, end-to-end Kubernetes cluster monitoring with <a href="https://prometheus.io/">Prometheus</a> using the <a href="https://github.com/prometheus-operator/prometheus-operator">Prometheus Operator</a>.</p><p><a href="https://raw.githubusercontent.com/cncf/artwork/40e2e8948509b40e4bad479446aaec18d6273bf2/projects/prometheus/horizontal/color/prometheus-horizontal-color.svg" class="popup img-link shimmer"><img src="https://raw.githubusercontent.com/cncf/artwork/40e2e8948509b40e4bad479446aaec18d6273bf2/projects/prometheus/horizontal/color/prometheus-horizontal-color.svg" alt="Prometheus" width="500" loading="lazy"></a></p><p>Install the <code class="language-plaintext highlighter-rouge">kube-prometheus-stack</code> <a href="https://artifacthub.io/packages/helm/prometheus-community/kube-prometheus-stack">Helm chart</a> and modify its <a href="https://github.com/prometheus-community/helm-charts/blob/kube-prometheus-stack-56.6.2/charts/kube-prometheus-stack/values.yaml">default values</a>:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
</pre><td class="rouge-code"><pre><span class="c"># renovate: datasource=helm depName=kube-prometheus-stack registryUrl=https://prometheus-community.github.io/helm-charts</span>
<span class="nv">KUBE_PROMETHEUS_STACK_HELM_CHART_VERSION</span><span class="o">=</span><span class="s2">"56.6.2"</span>

helm repo add <span class="nt">--force-update</span> prometheus-community https://prometheus-community.github.io/helm-charts
<span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-kube-prometheus-stack.yml"</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh">
defaultRules:
  rules:
    etcd: false
    kubernetesSystem: false
    kubeScheduler: false
alertmanager:
  config:
    global:
      smtp_smarthost: "mailhog.mailhog.svc.cluster.local:1025"
      smtp_from: "alertmanager@</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">"
    route:
      group_by: ["alertname", "job"]
      receiver: email-notifications
      routes:
        - receiver: email-notifications
          matchers: [ '{severity=~"warning|critical"}' ]
    receivers:
      - name: email-notifications
        email_configs:
          - to: "notification@</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">"
            require_tls: false
  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      forecastle.stakater.com/expose: "true"
      forecastle.stakater.com/icon: https://raw.githubusercontent.com/stakater/ForecastleIcons/master/alert-manager.png
      forecastle.stakater.com/appName: Alert Manager
      nginx.ingress.kubernetes.io/auth-url: https://oauth2-proxy.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">/oauth2/auth
      nginx.ingress.kubernetes.io/auth-signin: https://oauth2-proxy.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">/oauth2/start?rd=</span><span class="se">\$</span><span class="sh">scheme://</span><span class="se">\$</span><span class="sh">host</span><span class="se">\$</span><span class="sh">request_uri
    hosts:
      - alertmanager.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
    paths: ["/"]
    pathType: ImplementationSpecific
    tls:
      - hosts:
          - alertmanager.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
# https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml
grafana:
  defaultDashboardsEnabled: false
  serviceMonitor:
    enabled: true
  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      forecastle.stakater.com/expose: "true"
      forecastle.stakater.com/icon: https://raw.githubusercontent.com/stakater/ForecastleIcons/master/grafana.png
      forecastle.stakater.com/appName: Grafana
      nginx.ingress.kubernetes.io/auth-url: https://oauth2-proxy.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">/oauth2/auth
      nginx.ingress.kubernetes.io/auth-signin: https://oauth2-proxy.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">/oauth2/start?rd=</span><span class="se">\$</span><span class="sh">scheme://</span><span class="se">\$</span><span class="sh">host</span><span class="se">\$</span><span class="sh">request_uri
      nginx.ingress.kubernetes.io/configuration-snippet: |
        auth_request_set </span><span class="se">\$</span><span class="sh">email </span><span class="se">\$</span><span class="sh">upstream_http_x_auth_request_email;
        proxy_set_header X-Email </span><span class="se">\$</span><span class="sh">email;
    hosts:
      - grafana.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
    paths: ["/"]
    pathType: ImplementationSpecific
    tls:
      - hosts:
          - grafana.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
  datasources:
    datasource.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://kube-prometheus-stack-prometheus.kube-prometheus-stack:9090/
          access: proxy
          isDefault: true
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: "default"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default
  dashboards:
    default:
      1860-node-exporter-full:
        # renovate: depName="Node Exporter Full"
        gnetId: 1860
        revision: 33
        datasource: Prometheus
      3662-prometheus-2-0-overview:
        # renovate: depName="Prometheus 2.0 Overview"
        gnetId: 3662
        revision: 2
        datasource: Prometheus
      9852-stians-disk-graphs:
        # renovate: depName="node-exporter disk graphs"
        gnetId: 9852
        revision: 1
        datasource: Prometheus
      12006-kubernetes-apiserver:
        # renovate: depName="Kubernetes apiserver"
        gnetId: 12006
        revision: 1
        datasource: Prometheus
      9614-nginx-ingress-controller:
        # renovate: depName="NGINX Ingress controller"
        gnetId: 9614
        revision: 1
        datasource: Prometheus
      11875-kubernetes-ingress-nginx-eks:
        # renovate: depName="Kubernetes Ingress Nginx - EKS"
        gnetId: 11875
        revision: 1
        datasource: Prometheus
      15038-external-dns:
        # renovate: depName="External-dns"
        gnetId: 15038
        revision: 3
        datasource: Prometheus
      14314-kubernetes-nginx-ingress-controller-nextgen-devops-nirvana:
        # renovate: depName="Kubernetes Nginx Ingress Prometheus NextGen"
        gnetId: 14314
        revision: 2
        datasource: Prometheus
      13473-portefaix-kubernetes-cluster-overview:
        # renovate: depName="Portefaix / Kubernetes cluster Overview"
        gnetId: 13473
        revision: 2
        datasource: Prometheus
      # https://grafana.com/orgs/imrtfm/dashboards - https://github.com/dotdc/grafana-dashboards-kubernetes
      15760-kubernetes-views-pods:
        # renovate: depName="Kubernetes / Views / Pods"
        gnetId: 15760
        revision: 26
        datasource: Prometheus
      15757-kubernetes-views-global:
        # renovate: depName="Kubernetes / Views / Global"
        gnetId: 15757
        revision: 37
        datasource: Prometheus
      15758-kubernetes-views-namespaces:
        # renovate: depName="Kubernetes / Views / Namespaces"
        gnetId: 15758
        revision: 34
        datasource: Prometheus
      15759-kubernetes-views-nodes:
        # renovate: depName="Kubernetes / Views / Nodes"
        gnetId: 15759
        revision: 29
        datasource: Prometheus
      15761-kubernetes-system-api-server:
        # renovate: depName="Kubernetes / System / API Server"
        gnetId: 15761
        revision: 16
        datasource: Prometheus
      15762-kubernetes-system-coredns:
        # renovate: depName="Kubernetes / System / CoreDNS"
        gnetId: 15762
        revision: 17
        datasource: Prometheus
      19105-prometheus:
        # renovate: depName="Prometheus"
        gnetId: 19105
        revision: 3
        datasource: Prometheus
      16237-cluster-capacity:
        # renovate: depName="Cluster Capacity (Karpenter)"
        gnetId: 16237
        revision: 1
        datasource: Prometheus
      16236-pod-statistic:
        # renovate: depName="Pod Statistic (Karpenter)"
        gnetId: 16236
        revision: 1
        datasource: Prometheus
      19268-prometheus:
        # renovate: depName="Prometheus All Metrics"
        gnetId: 19268
        revision: 1
        datasource: Prometheus
  grafana.ini:
    analytics:
      check_for_updates: false
    server:
      root_url: https://grafana.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
    # Use oauth2-proxy instead of default Grafana Oauth
    auth.basic:
      enabled: false
    auth.proxy:
      enabled: true
      header_name: X-Email
      header_property: email
    users:
      auto_assign_org_role: Admin
  smtp:
    enabled: true
    host: "mailhog.mailhog.svc.cluster.local:1025"
    from_address: grafana@</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
  networkPolicy:
    enabled: true
kubeControllerManager:
  enabled: false
kubeEtcd:
  enabled: false
kubeScheduler:
  enabled: false
kubeProxy:
  enabled: false
kube-state-metrics:
  networkPolicy:
    enabled: true
prometheus-node-exporter:
  networkPolicy:
    enabled: true
prometheusOperator:
  tls:
    enabled: false
  admissionWebhooks:
    enabled: false
  networkPolicy:
    enabled: true
prometheus:
  networkPolicy:
    enabled: false
  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      forecastle.stakater.com/expose: "true"
      forecastle.stakater.com/icon: https://raw.githubusercontent.com/cncf/artwork/master/projects/prometheus/icon/color/prometheus-icon-color.svg
      forecastle.stakater.com/appName: Prometheus
      nginx.ingress.kubernetes.io/auth-url: https://oauth2-proxy.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">/oauth2/auth
      nginx.ingress.kubernetes.io/auth-signin: https://oauth2-proxy.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">/oauth2/start?rd=</span><span class="se">\$</span><span class="sh">scheme://</span><span class="se">\$</span><span class="sh">host</span><span class="se">\$</span><span class="sh">request_uri
    paths: ["/"]
    pathType: ImplementationSpecific
    hosts:
      - prometheus.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
    tls:
      - hosts:
          - prometheus.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
  prometheusSpec:
    externalLabels:
      cluster: </span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
    externalUrl: https://prometheus.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
    ruleSelectorNilUsesHelmValues: false
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    retentionSize: 1GB
    walCompression: true
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp2
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 2Gi
</span><span class="no">EOF
</span>helm upgrade <span class="nt">--install</span> <span class="nt">--version</span> <span class="s2">"</span><span class="k">${</span><span class="nv">KUBE_PROMETHEUS_STACK_HELM_CHART_VERSION</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--namespace</span> kube-prometheus-stack <span class="nt">--create-namespace</span> <span class="nt">--values</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-kube-prometheus-stack.yml"</span> kube-prometheus-stack prometheus-community/kube-prometheus-stack
</pre></table></code></div></div><h3 id="karpenter-1"><span class="me-2">karpenter</span><a href="#karpenter-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Customize the <a href="https://karpenter.sh/">karpenter</a> default installation by upgrading its <a href="https://artifacthub.io/packages/helm/oci-karpenter/karpenter">Helm chart</a> and modifying the <a href="https://github.com/aws/karpenter/blob/v0.31.4/charts/karpenter/values.yaml">default values</a>:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="c"># renovate: datasource=github-tags depName=aws/karpenter extractVersion=^(?&lt;version&gt;.*)$</span>
<span class="nv">KARPENTER_HELM_CHART_VERSION</span><span class="o">=</span><span class="s2">"v0.31.4"</span>

<span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-karpenter.yml"</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh">
replicas: 1
serviceMonitor:
  enabled: true
settings:
  aws:
    enablePodENI: true
    reservedENIs: "1"
</span><span class="no">EOF
</span>helm upgrade <span class="nt">--install</span> <span class="nt">--version</span> <span class="s2">"</span><span class="k">${</span><span class="nv">KARPENTER_HELM_CHART_VERSION</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--namespace</span> karpenter <span class="nt">--reuse-values</span> <span class="nt">--values</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-karpenter.yml"</span> karpenter oci://public.ecr.aws/karpenter/karpenter
</pre></table></code></div></div><h3 id="cert-manager"><span class="me-2">cert-manager</span><a href="#cert-manager" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="https://cert-manager.io/">cert-manager</a> adds certificates and certificate issuers as resource types in Kubernetes clusters. It also simplifies the process of obtaining, renewing, and using those certificates.</p><p><a href="https://raw.githubusercontent.com/cert-manager/cert-manager/7f15787f0f146149d656b6877a6fbf4394fe9965/logo/logo.svg" class="popup img-link shimmer"><img src="https://raw.githubusercontent.com/cert-manager/cert-manager/7f15787f0f146149d656b6877a6fbf4394fe9965/logo/logo.svg" alt="cert-manager" width="200" loading="lazy"></a></p><p>The <code class="language-plaintext highlighter-rouge">cert-manager</code> service account was previously created by <code class="language-plaintext highlighter-rouge">eksctl</code>. Install the <code class="language-plaintext highlighter-rouge">cert-manager</code> <a href="https://artifacthub.io/packages/helm/cert-manager/cert-manager">Helm chart</a> and modify its <a href="https://github.com/cert-manager/cert-manager/blob/v1.14.3/deploy/charts/cert-manager/values.yaml">default values</a>:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
</pre><td class="rouge-code"><pre><span class="c"># renovate: datasource=helm depName=cert-manager registryUrl=https://charts.jetstack.io</span>
<span class="nv">CERT_MANAGER_HELM_CHART_VERSION</span><span class="o">=</span><span class="s2">"1.14.3"</span>

helm repo add <span class="nt">--force-update</span> jetstack https://charts.jetstack.io
<span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-cert-manager.yml"</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh">
installCRDs: true
serviceAccount:
  create: false
  name: cert-manager
extraArgs:
  - --cluster-resource-namespace=cert-manager
  - --enable-certificate-owner-ref=true
securityContext:
  fsGroup: 1001
prometheus:
  servicemonitor:
    enabled: true
webhook:
  networkPolicy:
    enabled: true
</span><span class="no">EOF
</span>helm upgrade <span class="nt">--install</span> <span class="nt">--version</span> <span class="s2">"</span><span class="k">${</span><span class="nv">CERT_MANAGER_HELM_CHART_VERSION</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--namespace</span> cert-manager <span class="nt">--create-namespace</span> <span class="nt">--wait</span> <span class="nt">--values</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-cert-manager.yml"</span> cert-manager jetstack/cert-manager
</pre></table></code></div></div><p>Add ClusterIssuers for the Let’s Encrypt staging environment:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre><td class="rouge-code"><pre><span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/k8s-cert-manager-clusterissuer-staging.yml"</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-staging-dns
  namespace: cert-manager
  labels:
    letsencrypt: staging
spec:
  acme:
    server: https://acme-staging-v02.api.letsencrypt.org/directory
    email: </span><span class="k">${</span><span class="nv">MY_EMAIL</span><span class="k">}</span><span class="sh">
    privateKeySecretRef:
      name: letsencrypt-staging-dns
    solvers:
      - selector:
          dnsZones:
            - </span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
        dns01:
          route53:
            region: </span><span class="k">${</span><span class="nv">AWS_DEFAULT_REGION</span><span class="k">}</span><span class="sh">
</span><span class="no">EOF

</span>kubectl <span class="nb">wait</span> <span class="nt">--namespace</span> cert-manager <span class="nt">--timeout</span><span class="o">=</span>15m <span class="nt">--for</span><span class="o">=</span><span class="nv">condition</span><span class="o">=</span>Ready clusterissuer <span class="nt">--all</span>
</pre></table></code></div></div><p>Create the certificate:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre><span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/k8s-cert-manager-certificate-staging.yml"</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: ingress-cert-staging
  namespace: cert-manager
  labels:
    letsencrypt: staging
spec:
  secretName: ingress-cert-staging
  secretTemplate:
    labels:
      letsencrypt: staging
  issuerRef:
    name: letsencrypt-staging-dns
    kind: ClusterIssuer
  commonName: "*.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">"
  dnsNames:
    - "*.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">"
    - "</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">"
</span><span class="no">EOF
</span></pre></table></code></div></div><h3 id="external-dns"><span class="me-2">external-dns</span><a href="#external-dns" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="https://github.com/kubernetes-sigs/external-dns">ExternalDNS</a> synchronizes exposed Kubernetes Services and Ingresses with DNS providers.</p><p><a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/afe3b09f45a241750ec3ddceef59ceaf84c096d0/docs/img/external-dns.png" class="popup img-link shimmer"><img src="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/afe3b09f45a241750ec3ddceef59ceaf84c096d0/docs/img/external-dns.png" alt="ExternalDNS" width="300" loading="lazy"></a></p><p>ExternalDNS will manage the DNS records. The <code class="language-plaintext highlighter-rouge">external-dns</code> service account was previously created by <code class="language-plaintext highlighter-rouge">eksctl</code>. Install the <code class="language-plaintext highlighter-rouge">external-dns</code> <a href="https://artifacthub.io/packages/helm/external-dns/external-dns">Helm chart</a> and modify its <a href="https://github.com/kubernetes-sigs/external-dns/blob/external-dns-helm-chart-1.14.3/charts/external-dns/values.yaml">default values</a>:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre><span class="c"># renovate: datasource=helm depName=external-dns registryUrl=https://kubernetes-sigs.github.io/external-dns/</span>
<span class="nv">EXTERNAL_DNS_HELM_CHART_VERSION</span><span class="o">=</span><span class="s2">"1.14.3"</span>

helm repo add <span class="nt">--force-update</span> external-dns https://kubernetes-sigs.github.io/external-dns/
<span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-external-dns.yml"</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh">
domainFilters:
  - </span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
interval: 20s
policy: sync
serviceAccount:
  create: false
  name: external-dns
serviceMonitor:
  enabled: true
</span><span class="no">EOF
</span>helm upgrade <span class="nt">--install</span> <span class="nt">--version</span> <span class="s2">"</span><span class="k">${</span><span class="nv">EXTERNAL_DNS_HELM_CHART_VERSION</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--namespace</span> external-dns <span class="nt">--values</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-external-dns.yml"</span> external-dns external-dns/external-dns
</pre></table></code></div></div><h3 id="ingress-nginx"><span class="me-2">ingress-nginx</span><a href="#ingress-nginx" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="https://kubernetes.github.io/ingress-nginx/">ingress-nginx</a> is an Ingress controller for Kubernetes that uses <a href="https://www.nginx.org/">nginx</a> as a reverse proxy and load balancer.</p><p>Install the <code class="language-plaintext highlighter-rouge">ingress-nginx</code> <a href="https://artifacthub.io/packages/helm/ingress-nginx/ingress-nginx">Helm chart</a> and modify its <a href="https://github.com/kubernetes/ingress-nginx/blob/helm-chart-4.9.1/charts/ingress-nginx/values.yaml">default values</a>:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
</pre><td class="rouge-code"><pre><span class="c"># renovate: datasource=helm depName=ingress-nginx registryUrl=https://kubernetes.github.io/ingress-nginx</span>
<span class="nv">INGRESS_NGINX_HELM_CHART_VERSION</span><span class="o">=</span><span class="s2">"4.9.1"</span>

kubectl <span class="nb">wait</span> <span class="nt">--namespace</span> cert-manager <span class="nt">--for</span><span class="o">=</span><span class="nv">condition</span><span class="o">=</span>Ready <span class="nt">--timeout</span><span class="o">=</span>10m certificate ingress-cert-staging

helm repo add <span class="nt">--force-update</span> ingress-nginx https://kubernetes.github.io/ingress-nginx
<span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-ingress-nginx.yml"</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh">
controller:
  allowSnippetAnnotations: true
  ingressClassResource:
    default: true
  admissionWebhooks:
    networkPolicyEnabled: true
  extraArgs:
    default-ssl-certificate: "cert-manager/ingress-cert-staging"
  service:
    annotations:
      service.beta.kubernetes.io/aws-load-balancer-type: nlb
      service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags: </span><span class="k">${</span><span class="nv">TAGS</span><span class="p">//\</span><span class="s1">'/}
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
    prometheusRule:
      enabled: true
      rules:
        - alert: NGINXConfigFailed
          expr: count(nginx_ingress_controller_config_last_reload_successful == 0) &gt; 0
          for: 1s
          labels:
            severity: critical
          annotations:
            description: bad ingress config - nginx config test failed
            summary: uninstall the latest ingress changes to allow config reloads to resume
        - alert: NGINXCertificateExpiry
          expr: (avg(nginx_ingress_controller_ssl_expire_time_seconds) by (host) - time()) &lt; 604800
          for: 1s
          labels:
            severity: critical
          annotations:
            description: ssl certificate(s) will expire in less then a week
            summary: renew expiring certificates to avoid downtime
        - alert: NGINXTooMany500s
          expr: 100 * ( sum( nginx_ingress_controller_requests{status=~"5.+"} ) / sum(nginx_ingress_controller_requests) ) &gt; 5
          for: 1m
          labels:
            severity: warning
          annotations:
            description: Too many 5XXs
            summary: More than 5% of all requests returned 5XX, this requires your attention
        - alert: NGINXTooMany400s
          expr: 100 * ( sum( nginx_ingress_controller_requests{status=~"4.+"} ) / sum(nginx_ingress_controller_requests) ) &gt; 5
          for: 1m
          labels:
            severity: warning
          annotations:
            description: Too many 4XXs
            summary: More than 5% of all requests returned 4XX, this requires your attention
EOF
helm upgrade --install --version "${INGRESS_NGINX_HELM_CHART_VERSION}" --namespace ingress-nginx --create-namespace --wait --values "${TMP_DIR}/${CLUSTER_FQDN}/helm_values-ingress-nginx.yml" ingress-nginx ingress-nginx/ingress-nginx
</span></pre></table></code></div></div><h3 id="forecastle"><span class="me-2">forecastle</span><a href="#forecastle" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="https://github.com/stakater/Forecastle">Forecastle</a> is a control panel that dynamically discovers and provides a launchpad for accessing applications deployed on Kubernetes.</p><p><a href="https://raw.githubusercontent.com/stakater/Forecastle/c70cc130b5665be2649d00101670533bba66df0c/frontend/public/logo512.png" class="popup img-link shimmer"><img src="https://raw.githubusercontent.com/stakater/Forecastle/c70cc130b5665be2649d00101670533bba66df0c/frontend/public/logo512.png" alt="Forecastle" width="200" loading="lazy"></a></p><p>Install the <code class="language-plaintext highlighter-rouge">forecastle</code> <a href="https://artifacthub.io/packages/helm/stakater/forecastle">Helm chart</a> and modify its <a href="https://github.com/stakater/Forecastle/blob/v1.0.136/deployments/kubernetes/chart/forecastle/values.yaml">default values</a>:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre><td class="rouge-code"><pre><span class="c"># renovate: datasource=helm depName=forecastle registryUrl=https://stakater.github.io/stakater-charts</span>
<span class="nv">FORECASTLE_HELM_CHART_VERSION</span><span class="o">=</span><span class="s2">"1.0.136"</span>

helm repo add <span class="nt">--force-update</span> stakater https://stakater.github.io/stakater-charts
<span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-forecastle.yml"</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh">
forecastle:
  config:
    namespaceSelector:
      any: true
    title: Launch Pad
  networkPolicy:
    enabled: true
  ingress:
    enabled: true
    annotations:
      nginx.ingress.kubernetes.io/auth-signin: https://oauth2-proxy.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">/oauth2/start?rd=</span><span class="se">\$</span><span class="sh">scheme://</span><span class="se">\$</span><span class="sh">host</span><span class="se">\$</span><span class="sh">request_uri
      nginx.ingress.kubernetes.io/auth-url: https://oauth2-proxy.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">/oauth2/auth
    className: nginx
    hosts:
      - host: </span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
        paths:
          - path: /
            pathType: Prefix
    tls:
      - hosts:
          - </span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
</span><span class="no">EOF
</span>helm upgrade <span class="nt">--install</span> <span class="nt">--version</span> <span class="s2">"</span><span class="k">${</span><span class="nv">FORECASTLE_HELM_CHART_VERSION</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--namespace</span> forecastle <span class="nt">--create-namespace</span> <span class="nt">--values</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-forecastle.yml"</span> forecastle stakater/forecastle
</pre></table></code></div></div><h3 id="oauth2-proxy"><span class="me-2">oauth2-proxy</span><a href="#oauth2-proxy" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Use <a href="https://oauth2-proxy.github.io/oauth2-proxy/">OAuth2 Proxy</a> to protect the application endpoints with Google Authentication.</p><p><a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/899c743afc71e695964165deb11f50b9a0703c97/docs/static/img/logos/OAuth2_Proxy_horizontal.svg" class="popup img-link shimmer"><img src="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/899c743afc71e695964165deb11f50b9a0703c97/docs/static/img/logos/OAuth2_Proxy_horizontal.svg" alt="OAuth2 Proxy" width="400" loading="lazy"></a></p><p>Install the <code class="language-plaintext highlighter-rouge">oauth2-proxy</code> <a href="https://artifacthub.io/packages/helm/oauth2-proxy/oauth2-proxy">Helm chart</a> and modify its <a href="https://github.com/oauth2-proxy/manifests/blob/oauth2-proxy-6.24.1/helm/oauth2-proxy/values.yaml">default values</a>:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre><td class="rouge-code"><pre><span class="c"># renovate: datasource=helm depName=oauth2-proxy registryUrl=https://oauth2-proxy.github.io/manifests</span>
<span class="nv">OAUTH2_PROXY_HELM_CHART_VERSION</span><span class="o">=</span><span class="s2">"6.24.1"</span>

helm repo add <span class="nt">--force-update</span> oauth2-proxy https://oauth2-proxy.github.io/manifests
<span class="nb">tee</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-oauth2-proxy.yml"</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh">
config:
  clientID: </span><span class="k">${</span><span class="nv">GOOGLE_CLIENT_ID</span><span class="k">}</span><span class="sh">
  clientSecret: </span><span class="k">${</span><span class="nv">GOOGLE_CLIENT_SECRET</span><span class="k">}</span><span class="sh">
  cookieSecret: "</span><span class="si">$(</span>openssl rand <span class="nt">-base64</span> 32 | <span class="nb">head</span> <span class="nt">-c</span> 32 | <span class="nb">base64</span><span class="si">)</span><span class="sh">"
  configFile: |-
    cookie_domains = ".</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">"
    set_authorization_header = "true"
    set_xauthrequest = "true"
    upstreams = [ "file:///dev/null" ]
    whitelist_domains = ".</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">"
authenticatedEmailsFile:
  enabled: true
  restricted_access: |-
    </span><span class="k">${</span><span class="nv">MY_EMAIL</span><span class="k">}</span><span class="sh">
ingress:
  enabled: true
  className: nginx
  hosts:
    - oauth2-proxy.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
  tls:
    - hosts:
        - oauth2-proxy.</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="sh">
metrics:
  servicemonitor:
    enabled: true
</span><span class="no">EOF
</span>helm upgrade <span class="nt">--install</span> <span class="nt">--version</span> <span class="s2">"</span><span class="k">${</span><span class="nv">OAUTH2_PROXY_HELM_CHART_VERSION</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--namespace</span> oauth2-proxy <span class="nt">--create-namespace</span> <span class="nt">--values</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">/helm_values-oauth2-proxy.yml"</span> oauth2-proxy oauth2-proxy/oauth2-proxy
</pre></table></code></div></div><h2 id="clean-up"><span class="me-2">Clean-up</span><a href="#clean-up" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://raw.githubusercontent.com/aws-samples/eks-workshop/65b766c494a5b4f5420b2912d8373c4957163541/static/images/cleanup.svg" class="popup img-link shimmer"><img src="https://raw.githubusercontent.com/aws-samples/eks-workshop/65b766c494a5b4f5420b2912d8373c4957163541/static/images/cleanup.svg" alt="Clean-up" width="400" loading="lazy"></a></p><p>Remove the EKS cluster and its created components:</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="k">if </span>eksctl get cluster <span class="nt">--name</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">"</span><span class="p">;</span> <span class="k">then
  </span>eksctl delete cluster <span class="nt">--name</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--force</span>
<span class="k">fi</span>
</pre></table></code></div></div><p>Remove the Route 53 DNS records from the DNS Zone:</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="nv">CLUSTER_FQDN_ZONE_ID</span><span class="o">=</span><span class="si">$(</span>aws route53 list-hosted-zones <span class="nt">--query</span> <span class="s2">"HostedZones[?Name==</span><span class="se">\`</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">.</span><span class="se">\`</span><span class="s2">].Id"</span> <span class="nt">--output</span> text<span class="si">)</span>
<span class="k">if</span> <span class="o">[[</span> <span class="nt">-n</span> <span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_FQDN_ZONE_ID</span><span class="k">}</span><span class="s2">"</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then
  </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_FQDN_ZONE_ID</span><span class="k">}</span><span class="s2">"</span> | jq <span class="nt">-c</span> <span class="s1">'.ResourceRecordSets[] | select (.Type != "SOA" and .Type != "NS")'</span> |
    <span class="k">while </span><span class="nb">read</span> <span class="nt">-r</span> RESOURCERECORDSET<span class="p">;</span> <span class="k">do
      </span>aws route53 change-resource-record-sets <span class="se">\</span>
        <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_FQDN_ZONE_ID</span><span class="k">}</span><span class="s2">"</span> <span class="se">\</span>
        <span class="nt">--change-batch</span> <span class="s1">'{"Changes":[{"Action":"DELETE","ResourceRecordSet": '</span><span class="s2">"</span><span class="k">${</span><span class="nv">RESOURCERECORDSET</span><span class="k">}</span><span class="s2">"</span><span class="s1">' }]}'</span> <span class="se">\</span>
        <span class="nt">--output</span> text <span class="nt">--query</span> <span class="s1">'ChangeInfo.Id'</span>
    <span class="k">done
fi</span>
</pre></table></code></div></div><p>Remove any orphan EC2 instances created by Karpenter:</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="k">for </span>EC2 <span class="k">in</span> <span class="si">$(</span>aws ec2 describe-instances <span class="nt">--filters</span> <span class="s2">"Name=tag:kubernetes.io/cluster/</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">,Values=owned"</span> <span class="nv">Name</span><span class="o">=</span>instance-state-name,Values<span class="o">=</span>running <span class="nt">--query</span> <span class="s2">"Reservations[].Instances[].InstanceId"</span> <span class="nt">--output</span> text<span class="si">)</span><span class="p">;</span> <span class="k">do
  </span><span class="nb">echo</span> <span class="s2">"Removing EC2: </span><span class="k">${</span><span class="nv">EC2</span><span class="k">}</span><span class="s2">"</span>
  aws ec2 terminate-instances <span class="nt">--instance-ids</span> <span class="s2">"</span><span class="k">${</span><span class="nv">EC2</span><span class="k">}</span><span class="s2">"</span>
<span class="k">done</span>
</pre></table></code></div></div><p>Remove the CloudWatch log group:</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="k">if</span> <span class="o">[[</span> <span class="s2">"</span><span class="si">$(</span>aws logs describe-log-groups <span class="nt">--query</span> <span class="s2">"logGroups[?logGroupName==</span><span class="se">\`</span><span class="s2">/aws/eks/</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">/cluster</span><span class="se">\`</span><span class="s2">] | [0].logGroupName"</span> <span class="nt">--output</span> text<span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"/aws/eks/</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">/cluster"</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then
  </span>aws logs delete-log-group <span class="nt">--log-group-name</span> <span class="s2">"/aws/eks/</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">/cluster"</span>
<span class="k">fi</span>
</pre></table></code></div></div><p>Remove the CloudFormation stack:</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>aws cloudformation delete-stack <span class="nt">--stack-name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">-route53"</span>
</pre></table></code></div></div><p>Wait for all CloudFormation stacks to complete deletion:</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>aws cloudformation <span class="nb">wait </span>stack-delete-complete <span class="nt">--stack-name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">-route53"</span>
aws cloudformation <span class="nb">wait </span>stack-delete-complete <span class="nt">--stack-name</span> <span class="s2">"eksctl-</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">-cluster"</span>
</pre></table></code></div></div><p>Remove volumes and snapshots related to the cluster (as a precaution):</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="k">for </span>VOLUME <span class="k">in</span> <span class="si">$(</span>aws ec2 describe-volumes <span class="nt">--filter</span> <span class="s2">"Name=tag:KubernetesCluster,Values=</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">"</span> <span class="s2">"Name=tag:kubernetes.io/cluster/</span><span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span><span class="s2">,Values=owned"</span> <span class="nt">--query</span> <span class="s1">'Volumes[].VolumeId'</span> <span class="nt">--output</span> text<span class="si">)</span><span class="p">;</span> <span class="k">do
  </span><span class="nb">echo</span> <span class="s2">"*** Removing Volume: </span><span class="k">${</span><span class="nv">VOLUME</span><span class="k">}</span><span class="s2">"</span>
  aws ec2 delete-volume <span class="nt">--volume-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">VOLUME</span><span class="k">}</span><span class="s2">"</span>
<span class="k">done</span>
</pre></table></code></div></div><p>Remove the <code class="language-plaintext highlighter-rouge">${TMP_DIR}/${CLUSTER_FQDN}</code> directory:</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="k">if</span> <span class="o">[[</span> <span class="nt">-d</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">"</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then
  for </span>FILE <span class="k">in</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">"</span>/<span class="o">{</span>kubeconfig-<span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span>.conf,<span class="o">{</span>aws-cf-route53,eksctl-<span class="k">${</span><span class="nv">CLUSTER_NAME</span><span class="k">}</span>,k8s-karpenter-provisioner,helm_values-<span class="o">{</span>aws-node-termination-handler,cert-manager,external-dns,forecastle,ingress-nginx,karpenter,kube-prometheus-stack,mailhog,oauth2-proxy<span class="o">}</span>,k8s-cert-manager-<span class="o">{</span>certificate,clusterissuer<span class="o">}</span><span class="nt">-staging</span><span class="o">}</span>.yml<span class="o">}</span><span class="p">;</span> <span class="k">do
    if</span> <span class="o">[[</span> <span class="nt">-f</span> <span class="s2">"</span><span class="k">${</span><span class="nv">FILE</span><span class="k">}</span><span class="s2">"</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then
      </span><span class="nb">rm</span> <span class="nt">-v</span> <span class="s2">"</span><span class="k">${</span><span class="nv">FILE</span><span class="k">}</span><span class="s2">"</span>
    <span class="k">else
      </span><span class="nb">echo</span> <span class="s2">"*** File not found: </span><span class="k">${</span><span class="nv">FILE</span><span class="k">}</span><span class="s2">"</span>
    <span class="k">fi
  done
  </span><span class="nb">rmdir</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">CLUSTER_FQDN</span><span class="k">}</span><span class="s2">"</span>
<span class="k">fi</span>
</pre></table></code></div></div><p>Enjoy … 😉</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/kubernetes/">Kubernetes</a>, <a href="/categories/amazon-eks/">Amazon EKS</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/amazon-eks/" class="post-tag no-text-decoration" >Amazon EKS</a> <a href="/tags/k8s/" class="post-tag no-text-decoration" >k8s</a> <a href="/tags/kubernetes/" class="post-tag no-text-decoration" >kubernetes</a> <a href="/tags/karpenter/" class="post-tag no-text-decoration" >karpenter</a> <a href="/tags/eksctl/" class="post-tag no-text-decoration" >eksctl</a> <a href="/tags/cert-manager/" class="post-tag no-text-decoration" >cert-manager</a> <a href="/tags/external-dns/" class="post-tag no-text-decoration" >external-dns</a> <a href="/tags/podinfo/" class="post-tag no-text-decoration" >podinfo</a></div><div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 " ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Run%20the%20cheapest%20Amazon%20EKS%20-%20Petr's%20Blog&url=https%3A%2F%2Fruzickap.github.io%2Fposts%2Fcheapest-amazon-eks%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter"> <i class="fa-fw fa-brands fa-square-x-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Run%20the%20cheapest%20Amazon%20EKS%20-%20Petr's%20Blog&u=https%3A%2F%2Fruzickap.github.io%2Fposts%2Fcheapest-amazon-eks%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fruzickap.github.io%2Fposts%2Fcheapest-amazon-eks%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Linkedin" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!" > <i class="fa-fw fas fa-link pe-none fs-6"></i> </button> </span></div></div></div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted"><div class="access"><section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2><ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2"><li class="text-truncate lh-lg"> <a href="/posts/amazon-eks-karpenter-tests/">Amazon EKS - Karpenter tests</a><li class="text-truncate lh-lg"> <a href="/posts/eks-auto-cert-manager-velero/">Amazon EKS Auto Mode with cert-manager and Velero</a><li class="text-truncate lh-lg"> <a href="/posts/secure-cheap-amazon-eks-auto/">Build secure and cheap Amazon EKS Auto Mode</a><li class="text-truncate lh-lg"> <a href="/posts/mcp-servers-k8s/">MCP Servers running on Kubernetes</a><li class="text-truncate lh-lg"> <a href="/posts/ollama-k8s-exploitation/">Exploiting RCE Vulnerabilities in Ollama on Kubernetes</a></ul></section><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/kubernetes/">kubernetes</a> <a class="post-tag btn btn-outline-primary" href="/tags/k8s/">k8s</a> <a class="post-tag btn btn-outline-primary" href="/tags/amazon-eks/">Amazon EKS</a> <a class="post-tag btn btn-outline-primary" href="/tags/eksctl/">eksctl</a> <a class="post-tag btn btn-outline-primary" href="/tags/security/">security</a> <a class="post-tag btn btn-outline-primary" href="/tags/cert-manager/">cert-manager</a> <a class="post-tag btn btn-outline-primary" href="/tags/external-dns/">external-dns</a> <a class="post-tag btn btn-outline-primary" href="/tags/amazon-eks/">amazon eks</a> <a class="post-tag btn btn-outline-primary" href="/tags/oauth2-proxy/">oauth2-proxy</a> <a class="post-tag btn btn-outline-primary" href="/tags/podinfo/">podinfo</a></div></section></div><div class="toc-border-cover z-3"></div><section id="toc-wrapper" class="invisible position-sticky ps-0 pe-4 pb-4"><h2 class="panel-heading ps-3 pb-2 mb-0">Contents</h2><nav id="toc"></nav></section></aside></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4"><aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3><nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/posts/cilium-amazon-eks/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1691013600" data-df="ll" > Aug 3, 2023 </time><h4 class="pt-0 my-2">Build secure Amazon EKS with Cilium and network encryption</h4><div class="text-muted"><p>Build "cheap and secure" Amazon EKS with Karpenter and Cilium</p></div></div></a></article><article class="col"> <a href="/posts/secure-cheap-amazon-eks/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1695592800" data-df="ll" > Sep 25, 2023 </time><h4 class="pt-0 my-2">Build secure and cheap Amazon EKS</h4><div class="text-muted"><p>Build "cheap and secure" Amazon EKS with network policies, cluster encryption and logging</p></div></div></a></article><article class="col"> <a href="/posts/secure-cheap-amazon-eks-with-pod-identities/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1714687200" data-df="ll" > May 3, 2024 </time><h4 class="pt-0 my-2">Build secure and cheap Amazon EKS with Pod Identities</h4><div class="text-muted"><p>Build "cheap and secure" Amazon EKS with Pod Identities, network policies, cluster encryption and logging</p></div></div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"> <a href="/posts/my-sony-a7-iv-settings/" class="btn btn-outline-primary" aria-label="Older" ><p>My Sony A7 IV settings</p></a> <a href="/posts/amazon-eks-karpenter-tests/" class="btn btn-outline-primary" aria-label="Newer" ><p>Amazon EKS - Karpenter tests</p></a></nav><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 " ><p>© <time>2025</time> <a href="https://twitter.com/Ruzicka_Petr">Petr Ruzicka</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author." >Some rights reserved.</span></p><p>Using the <a data-bs-toggle="tooltip" data-bs-placement="top" title="v7.4.1" href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener" >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.</p></footer></div></div><div id="search-result-wrapper" class="d-flex justify-content-center d-none"><div class="col-11 content"><div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/kubernetes/">kubernetes</a> <a class="post-tag btn btn-outline-primary" href="/tags/k8s/">k8s</a> <a class="post-tag btn btn-outline-primary" href="/tags/amazon-eks/">Amazon EKS</a> <a class="post-tag btn btn-outline-primary" href="/tags/eksctl/">eksctl</a> <a class="post-tag btn btn-outline-primary" href="/tags/security/">security</a> <a class="post-tag btn btn-outline-primary" href="/tags/cert-manager/">cert-manager</a> <a class="post-tag btn btn-outline-primary" href="/tags/external-dns/">external-dns</a> <a class="post-tag btn btn-outline-primary" href="/tags/amazon-eks/">amazon eks</a> <a class="post-tag btn btn-outline-primary" href="/tags/oauth2-proxy/">oauth2-proxy</a> <a class="post-tag btn btn-outline-primary" href="/tags/podinfo/">podinfo</a></div></section></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside></div><div id="mask" class="d-none position-fixed w-100 h-100 z-1"></div><aside id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-bs-animation="true" data-bs-autohide="false" ><div class="toast-header"> <button type="button" class="btn-close ms-auto" data-bs-dismiss="toast" aria-label="Close" ></button></div><div class="toast-body text-center pt-0"><p class="px-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></aside><script> (function () { const themeMapper = Theme.getThemeMapper('light', 'dark_dimmed'); const initTheme = themeMapper[Theme.visualState]; let lang = 'en';if (lang.length > 2 && !lang.startsWith('zh')) { lang = lang.slice(0, 2); } let giscusAttributes = { src: 'https://giscus.app/client.js', 'data-repo': 'ruzickap/ruzickap.github.io', 'data-repo-id': 'R_kgDOGkp4nQ', 'data-category': 'General', 'data-category-id': 'DIC_kwDOGkp4nc4CSdu1', 'data-mapping': 'pathname', 'data-strict' : '0', 'data-reactions-enabled': '1', 'data-emit-metadata': '0', 'data-theme': initTheme, 'data-input-position': 'bottom', 'data-lang': lang, 'data-loading': 'lazy', crossorigin: 'anonymous', async: '' }; let giscusNode = document.createElement('script'); Object.entries(giscusAttributes).forEach(([key, value]) => giscusNode.setAttribute(key, value) ); const $footer = document.querySelector('footer'); $footer.insertAdjacentElement("beforebegin", giscusNode); addEventListener('message', (event) => { if (event.source === window && event.data && event.data.id === Theme.ID) { const newTheme = themeMapper[Theme.visualState]; const message = { setConfig: { theme: newTheme } }; const giscus = document.getElementsByClassName('giscus-frame')[0].contentWindow; giscus.postMessage({ giscus: message }, 'https://giscus.app'); } }); })(); </script> <script> document.addEventListener('DOMContentLoaded', () => { SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{content}</p></article>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); }); </script>
